{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer learning Skeleton"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import PIL.Image as Image\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Acquisition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(ds_train, ds_test), ds_info = tfds.load(\n",
    "    'rock_paper_scissors',\n",
    "    split=['train', 'test'],\n",
    "    shuffle_files=True,\n",
    "    as_supervised=True,\n",
    "    with_info=True,\n",
    ")\n",
    "print(\"ds_info:\\n\", ds_info)\n",
    "num_classes = ds_info.features['label'].num_classes\n",
    "print(\"num_classes: \", num_classes)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_img(image, label):\n",
    "\n",
    "    # expected_image_shape \n",
    "    expected_image_shape = (224,224)\n",
    "\n",
    "\n",
    "    # Normalizes images: float32\n",
    "    # rescales pixel values between [0,1]\n",
    "    # resize image to expected_image_shape\n",
    "\n",
    "    ## image = tf.image.convert_image_dtype(image, dtype=tf.float16)/ 255.\n",
    "    image = tf.cast(image, tf.float32) / 255.\n",
    "    image = tf.image.resize(image, expected_image_shape)\n",
    "    label = tf.cast(tf.one_hot(label, num_classes), tf.uint8)\n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_data = ds_train.take(1)  # Only take a single example\n",
    "print(sample_data)\n",
    "\n",
    "for n in sample_data:\n",
    "    sign = Image.fromarray(n[0].numpy())\n",
    "    label = n[1].numpy()\n",
    "    print('labels: rock:0, paper:1, scissors:2')\n",
    "    print(\"label: \" + str(label))\n",
    "    display(sign)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normilize data and revert it back but rescale the final image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_data = sample_data.map(normalize_img)\n",
    "print(sample_data)\n",
    "\n",
    "for n in sample_data:\n",
    "    image = np.uint8(n[0].numpy()*255) \n",
    "\n",
    "\n",
    "    sign = Image.fromarray(image)\n",
    "    label = n[1].numpy()\n",
    "    print('labels: rock:0, paper:1, scissors:2')\n",
    "    print(\"label: \" + str(label))\n",
    "    display(sign)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data train test split\n",
    "\n",
    "\n",
    "performed in one method when downloaded from tfds.load"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Batch & Epoch variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16 \n",
    "epochs = 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Formating of Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data is cast to float32 and rescaled to between 0-1\n",
    "# resized to expected model input_shape\n",
    "\n",
    "ds_train = ds_train.map(normalize_img,num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "ds_test = ds_test.map(normalize_img, num_parallel_calls=tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# divide in batches\n",
    "\n",
    "ds_train = ds_train.cache()\n",
    "ds_train = ds_train.shuffle(ds_info.splits['train'].num_examples)\n",
    "\n",
    "ds_train_batch = ds_train.batch(batch_size, drop_remainder=True)\n",
    "ds_train = ds_train.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "print(ds_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### how to get 1 batch from the data\n",
    "\n",
    "`one_batch = ds_train.take(1)\n",
    "\n",
    "as_np = list(ds_train.take(1).as_numpy_iterator())`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_batch = ds_train_batch.take(1)  # Only take a single example\n",
    "print(sample_batch)\n",
    "print('\\n')\n",
    "\n",
    "image = list(sample_batch.as_numpy_iterator())[0][0][0]\n",
    "label = list(sample_batch.as_numpy_iterator())[0][1][0]\n",
    "\n",
    "image = np.uint8(image*255)\n",
    "image = Image.fromarray(image)\n",
    "print('labels: rock:0, paper:1, scissors:2')\n",
    "print(\"label: \" + str(label))\n",
    "display(sign)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  when not batchwise seperated\n",
    "sample_data = ds_train.take(1)  # Only take a single example\n",
    "print(sample_data)\n",
    "\n",
    "for n in sample_data:\n",
    "    image = np.uint8(n[0].numpy()*255) \n",
    "\n",
    "    sign = Image.fromarray(image)\n",
    "    label = n[1].numpy()\n",
    "    print('labels: rock:0, paper:1, scissors:2')\n",
    "    print(\"label: \" + str(label))\n",
    "    display(sign)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create/Download Base of model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decide on base model, (ex. EfficientNet-B0) - downloadable from tensorflow.hub\n",
    "\n",
    "##### Decide what you want to \"re-train\", final layer and/or layers within the model\n",
    "\n",
    "(Find expected image size) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_url = \"https://tfhub.dev/tensorflow/efficientnet/b0/feature-vector/1\"\n",
    "\n",
    "expected_input_shape = (224,224) \n",
    "\n",
    "feature_extractor = hub.KerasLayer(\n",
    "    classifier_url,\n",
    "    input_shape=expected_input_shape+(3,), \n",
    "    trainable=False) # Can be True, \"Fine tune\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Base-model on a batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction\n",
    "##### (Incase of deciding on a \"re-train\"-configuration for only the top-layer classifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test the feature extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_batch = ds_train_batch.take(1)\n",
    "as_np = list(one_batch.as_numpy_iterator())[0][0]\n",
    "\n",
    "print(feature_extractor(as_np))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Freeze the convolutional base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extractor.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add a Classification Head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "efn_model = tf.keras.Sequential([\n",
    "    feature_extractor,\n",
    "    tf.keras.layers.Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "\n",
    "efn_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the untrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "as_np = ds_train.take(1)\n",
    "for n in as_np:\n",
    "\n",
    "    image = np.uint8(n[0].numpy()*255) \n",
    "\n",
    "    sign = Image.fromarray(image)\n",
    "    label = n[1].numpy()\n",
    "    print('labels: rock:0, paper:1, scissors:2')\n",
    "    print(\"label: \" + str(label))\n",
    "    display(sign)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    sample = n[0][np.newaxis, ...]\n",
    "\n",
    "    predictions = efn_model(sample)\n",
    "    print(predictions)\n",
    "\n",
    "    predicted_class = np.argmax(predictions[0], axis=-1)\n",
    "    \n",
    "    print('Classes: \\n')\n",
    "    print('rock: 1, paper: 2, scissors: 3')\n",
    "    print(predicted_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "efn_model.compile(\n",
    "    loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "    optimizer=tf.keras.optimizers.Adam(),\n",
    "    metrics=['acc']\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Custom callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CollectBatchStats(tf.keras.callbacks.Callback):\n",
    "  def __init__(self):\n",
    "    self.batch_losses = []\n",
    "    self.batch_acc = []\n",
    "\n",
    "  def on_batch_end(self, batch, logs=None):\n",
    "    self.batch_losses.append(logs['loss'])\n",
    "    self.batch_acc.append(logs['acc'])\n",
    "    self.model.reset_metrics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_stats_callback = CollectBatchStats()\n",
    "\n",
    "print(ds_train_batch)\n",
    "\n",
    "history = efn_model.fit(ds_train_batch, \n",
    "                        epochs=2,\n",
    "                        callbacks = [batch_stats_callback],\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Learning curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.xlabel(\"Training Steps\")\n",
    "plt.ylim([0,2])\n",
    "plt.plot(batch_stats_callback.batch_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlabel(\"Training Steps\")\n",
    "plt.ylim([0,1])\n",
    "plt.plot(batch_stats_callback.batch_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine tuning\n",
    "In the feature extraction experiment, you were only training a few layers on top of an MobileNet V2 base model. The weights of the pre-trained network were **not** updated during training.\n",
    "\n",
    "One way to increase performance even further is to train (or \"fine-tune\") the weights of the top layers of the pre-trained model alongside the training of the classifier you added. The training process will force the weights to be tuned from generic feature maps to features associated specifically with the dataset.\n",
    "\n",
    "Note: This should only be attempted after you have trained the top-level classifier with the pre-trained model set to non-trainable. If you add a randomly initialized classifier on top of a pre-trained model and attempt to train all layers jointly, the magnitude of the gradient updates will be too large (due to the random weights from the classifier) and your pre-trained model will forget what it has learned.\n",
    "\n",
    "Also, you should try to fine-tune a small number of top layers rather than the whole MobileNet model. In most convolutional networks, the higher up a layer is, the more specialized it is. The first few layers learn very simple and generic features that generalize to almost all types of images. As you go higher up, the features are increasingly more specific to the dataset on which the model was trained. The goal of fine-tuning is to adapt these specialized features to work with the new dataset, rather than overwrite the generic learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Un-freeze the top layers of the model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Continue training the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Learning curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "INFO:tensorflow:Assets written to: C:/Users/sadhos/Documents/vansbro/tmp/saved_models/1590333259\\assets\nINFO:tensorflow:Assets written to: C:/Users/sadhos/Documents/vansbro/tmp/saved_models/1590333259\\assets\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "'C:/Users/sadhos/Documents/vansbro/tmp/saved_models/1590333259'"
     },
     "metadata": {},
     "execution_count": 30
    }
   ],
   "source": [
    "import time\n",
    "t = time.time()\n",
    "\n",
    "export_path = \"C:/Users/sadhos/Documents/vansbro/tmp/saved_models/{}\".format(int(t))\n",
    "efn_model.save(export_path, save_format='tf')\n",
    "\n",
    "export_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confirm model, by reloading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "reloaded = tf.keras.models.load_model(export_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_batch = model.predict(image_batch)\n",
    "reloaded_result_batch = reloaded.predict(image_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abs(reloaded_result_batch - result_batch).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python37564bitc8b9567430bb498fb445e60c888d52ad",
   "display_name": "Python 3.7.5 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}